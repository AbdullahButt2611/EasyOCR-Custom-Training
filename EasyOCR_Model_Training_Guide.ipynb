{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tuning EasyOCR for Custom Text Recognition"
      ],
      "metadata": {
        "id": "82AFSoH8jFv5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Overview\n",
        "This notebook demonstrates how to fine-tune EasyOCR's text recognition model on custom datasets. EasyOCR is a powerful OCR library, but sometimes the pre-trained models don't perform well on domain-specific text (technical jargon, special formatting, unique fonts, etc.). This guide shows you how to train a custom model to improve accuracy on your specific use case.\n",
        "\n",
        "### What You'll Learn\n",
        "How to prepare custom training data in LMDB format\n",
        "- Setting up the Deep Text Recognition Benchmark environment\n",
        "- Training a custom recognition model\n",
        "- Converting the trained model for use with EasyOCR\n",
        "- Testing your fine-tuned model\n",
        "\n",
        "### Prerequisites\n",
        "- Basic understanding of Python and machine learning\n",
        "- Training images with corresponding text labels\n",
        "- A `gt.txt` file containing image-label pairs (format: `image_filename.jpg<TAB>label_text`)\n",
        "\n",
        "### Training Data Format\n",
        "Your training data should be organized as:\n",
        "```\n",
        "train_data/\n",
        "â”œâ”€â”€ image1.jpg\n",
        "â”œâ”€â”€ image2.jpg\n",
        "â”œâ”€â”€ ...\n",
        "â””â”€â”€ gt.txt\n",
        "```\n",
        "\n",
        "The `gt.txt file` should contain tab-separated values:\n",
        "```\n",
        "image1.jpg\tsample text one\n",
        "image2.jpg\tanother sample\n",
        "```"
      ],
      "metadata": {
        "id": "ZyhiFEOrjVvN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Environment Setup\n",
        "First, we'll clean up any existing installations and prepare our workspace."
      ],
      "metadata": {
        "id": "Osx6ym9_kCdm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Grfxm-niqBT"
      },
      "outputs": [],
      "source": [
        "# Remove the old folder if it exists\n",
        "%cd /content/\n",
        "!rm -rf deep-text-recognition-benchmark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clone the Deep Text Recognition Benchmark Repository\n",
        "The Deep Text Recognition Benchmark is the underlying framework that powers EasyOCR's recognition models."
      ],
      "metadata": {
        "id": "VJhxDP7YkIti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the benchmark repository\n",
        "!git clone https://github.com/clovaai/deep-text-recognition-benchmark.git\n",
        "%cd deep-text-recognition-benchmark"
      ],
      "metadata": {
        "id": "fPd26EbHkRiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Required Dependencies"
      ],
      "metadata": {
        "id": "2GkN285ZkXRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install specific dependencies for LMDB\n",
        "!pip install lmdb pillow nltk natsort"
      ],
      "metadata": {
        "id": "1YdY3_mqkbfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fire"
      ],
      "metadata": {
        "id": "jMYkerSskdbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Data Preprocessing\n",
        "### Fix Ground Truth File Format\n",
        "This step ensures your ground truth file is properly formatted with tab separators between filenames and labels."
      ],
      "metadata": {
        "id": "meJH5QjZkfkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Script to fix the text file\n",
        "input_file = '../train_data/gt.txt'\n",
        "output_file = '../train_data/gt_fixed.txt'\n",
        "\n",
        "with open(input_file, 'r', encoding='utf-8') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "with open(output_file, 'w', encoding='utf-8') as f:\n",
        "    for line in lines:\n",
        "        # Strip whitespace from ends and skip empty lines\n",
        "        clean_line = line.strip()\n",
        "        if not clean_line:\n",
        "            continue\n",
        "\n",
        "        # If you accidentally used spaces, this replaces the first space with a tab\n",
        "        if '\\t' not in clean_line:\n",
        "            # Replaces the first sequence of spaces with a single tab\n",
        "            parts = clean_line.split(None, 1)\n",
        "            if len(parts) == 2:\n",
        "                f.write(f\"{parts[0]}\\t{parts[1]}\\n\")\n",
        "        else:\n",
        "            f.write(f\"{clean_line}\\n\")\n",
        "\n",
        "print(\"Fixed file created at: ../train_data/gt_fixed.txt\")"
      ],
      "metadata": {
        "id": "rcxx3f5NkksH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert Data to LMDB Format\n",
        "LMDB (Lightning Memory-Mapped Database) is an efficient storage format that speeds up data loading during training."
      ],
      "metadata": {
        "id": "t8aYR6ZiktKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Create the output directory\n",
        "os.makedirs('/train_lmdb', exist_ok=True)\n",
        "\n",
        "!python3 create_lmdb_dataset.py \\\n",
        "    --inputPath ../train_data/ \\\n",
        "    --gtFile ../train_data/gt_fixed.txt \\\n",
        "    --outputPath /train_lmdb/"
      ],
      "metadata": {
        "id": "2C-uvrU3kv-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Framework Compatibility Fixes\n",
        "### Fix PyTorch Compatibility Issue\n",
        "Recent versions of PyTorch have moved some internal utilities. This patch ensures compatibility."
      ],
      "metadata": {
        "id": "lJq3Sd6zkxrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix the ImportError by replacing the internal torch call with standard python itertools\n",
        "dataset_path = '/content/deep-text-recognition-benchmark/dataset.py'\n",
        "\n",
        "with open(dataset_path, 'r') as f:\n",
        "    content = f.read()\n",
        "\n",
        "# Replace the problematic import\n",
        "content = content.replace('from torch._utils import _accumulate', 'from itertools import accumulate as _accumulate')\n",
        "\n",
        "with open(dataset_path, 'w') as f:\n",
        "    f.write(content)\n",
        "\n",
        "print(\"Successfully patched dataset.py!\")"
      ],
      "metadata": {
        "id": "z3LEwcuNksmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configure for CPU Training\n",
        "If you're training on CPU (not recommended for large datasets), this step removes CUDA dependencies.\\\n",
        "\n",
        "> **Note:** \\\n",
        "> For faster training, use GPU runtime in Colab: Runtime â†’ Change runtime type â†’ GPU"
      ],
      "metadata": {
        "id": "Iz8mAzYllHY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This command uses 'sed' to replace all occurrences of '.cuda()' with nothing\n",
        "# essentially forcing the script to stay on the CPU.\n",
        "!sed -i 's/\\.cuda()//g' train.py\n",
        "!sed -i 's/device = torch.device('\\''cuda'\\'')/device = torch.device('\\''cpu'\\'')/g' train.py"
      ],
      "metadata": {
        "id": "7wOy0W8lliQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Model Training\n",
        "### Training Configuration\n",
        "The following parameters control the training process:\n",
        "- **Transformation**: None (no spatial transformation)\n",
        "- **FeatureExtraction**: VGG (convolutional feature extractor)\n",
        "- **SequenceModeling**: BiLSTM (bidirectional LSTM for sequence modeling)\n",
        "- **Prediction**: CTC (Connectionist Temporal Classification for alignment)\n",
        "- **batch_size**: 8 (adjust based on your GPU memory)\n",
        "- **num_iter**: 1000 (total training iterations)\n",
        "- **valInterval**: 100 (validation every 100 iterations)"
      ],
      "metadata": {
        "id": "I1t1E-7qlkki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 train.py \\\n",
        "    --exp_name my_easyocr_finetune \\\n",
        "    --train_data /train_lmdb/ \\\n",
        "    --valid_data /train_lmdb/ \\\n",
        "    --select_data / \\\n",
        "    --batch_ratio 1 \\\n",
        "    --Transformation None \\\n",
        "    --FeatureExtraction VGG \\\n",
        "    --SequenceModeling BiLSTM \\\n",
        "    --Prediction CTC \\\n",
        "    --batch_size 8 \\\n",
        "    --num_iter 1000 \\\n",
        "    --valInterval 100 \\\n",
        "    --workers 0"
      ],
      "metadata": {
        "id": "tIL25kzcl0Ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Output Interpretation:\n",
        "- **Train loss:** Should decrease over time\n",
        "- **Valid loss:** Should also decrease; watch for overfitting\n",
        "- **Current_accuracy:** Recognition accuracy on validation set\n",
        "- **Current_norm_ED:** Normalized edit distance (lower is better)\n",
        "\n",
        "> The model checkpoints will be saved in `saved_models/my_easyocr_finetune/`"
      ],
      "metadata": {
        "id": "fOgHLzBgl2DM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Model Conversion for EasyOCR\n",
        "### Return to Main Directory"
      ],
      "metadata": {
        "id": "2YtDbNCkmDoK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "id": "gN7Rl8LDmFE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install EasyOCR"
      ],
      "metadata": {
        "id": "g4rSsYGBmJ_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install easyocr"
      ],
      "metadata": {
        "id": "5gt3KkCvmKyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Required Libraries"
      ],
      "metadata": {
        "id": "KceZwkyomNux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import easyocr\n",
        "import shutil"
      ],
      "metadata": {
        "id": "xfbSL1qOmOaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert Model Weights to EasyOCR Format\n",
        "The trained model uses a different key naming convention than EasyOCR expects. This conversion script fixes that."
      ],
      "metadata": {
        "id": "lkZPSFmAmQ2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Path to your fine-tuned model\n",
        "input_model_path = 'user_network/custom_model.pth'  # Change this to your model path\n",
        "output_model_path = 'converted_model.pth'\n",
        "\n",
        "# Load the state dict\n",
        "print(\"Loading model...\")\n",
        "checkpoint = torch.load(input_model_path, map_location='cpu')\n",
        "\n",
        "# Handle different checkpoint formats\n",
        "if isinstance(checkpoint, dict) and 'state_dict' in checkpoint:\n",
        "    state_dict = checkpoint['state_dict']\n",
        "else:\n",
        "    state_dict = checkpoint\n",
        "\n",
        "# Create new state dict with corrected keys\n",
        "new_state_dict = {}\n",
        "\n",
        "print(\"\\nConverting keys...\")\n",
        "for old_key, value in state_dict.items():\n",
        "    # Replace FeatureExtraction.ConvNet. with FeatureExtraction.\n",
        "    if 'FeatureExtraction.ConvNet.' in old_key:\n",
        "        new_key = old_key.replace('FeatureExtraction.ConvNet.', 'FeatureExtraction.')\n",
        "        new_state_dict[new_key] = value\n",
        "        print(f\"  {old_key} -> {new_key}\")\n",
        "    else:\n",
        "        new_state_dict[old_key] = value\n",
        "\n",
        "# Save the converted model\n",
        "print(f\"\\nSaving converted model to {output_model_path}...\")\n",
        "torch.save(new_state_dict, output_model_path)\n",
        "\n",
        "print(\"\\nâœ“ Conversion complete!\")\n",
        "print(f\"\\nConverted {len(new_state_dict)} parameters\")\n",
        "print(\"\\nFirst 10 keys in converted model:\")\n",
        "for i, key in enumerate(list(new_state_dict.keys())[:10]):\n",
        "    print(f\"  {key}\")"
      ],
      "metadata": {
        "id": "jyr1w4_9mSR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Copy Converted Model to User Network Directory"
      ],
      "metadata": {
        "id": "KBLsEWgRmW9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, convert your model weights (run the conversion script I provided earlier)\n",
        "# Then copy the converted weights to the model storage directory\n",
        "shutil.copy('converted_model.pth', '/content/user_network/custom_model.pth')"
      ],
      "metadata": {
        "id": "n1uywfxamYSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Testing Your Custom Model\n",
        "Now let's test the fine-tuned model on some sample images."
      ],
      "metadata": {
        "id": "lVwJ6Ugamppf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reader = easyocr.Reader(\n",
        "    ['en'],\n",
        "    model_storage_directory='/content/user_network',\n",
        "    user_network_directory='/content/user_network',\n",
        "    recog_network='custom_model',\n",
        "    gpu=False\n",
        ")\n",
        "\n",
        "results = reader.readtext('input1.png')\n",
        "\n",
        "for res in results:\n",
        "    print(f\"Detected: {res[1]} (Confidence: {res[2]:.4f})\")"
      ],
      "metadata": {
        "id": "QahgRuvFmsXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tips for Better Results\n",
        "### 1. Data Quality\n",
        "- Use high-quality, clear images\n",
        "- Ensure consistent formatting across training samples\n",
        "- Include diverse examples of all characters/words you want to recognize\n",
        "\n",
        "### 2. Training Parameters\n",
        "- Increase num_iter for better convergence (`3000-5000` recommended)\n",
        "- Adjust `batch_size` based on available memory\n",
        "- Monitor validation metrics to prevent overfitting\n",
        "\n",
        "### 3. Model Architecture\n",
        "- Try different feature extractors: `ResNet`, `VGG`, `RCNN`\n",
        "- Experiment with different sequence models: `BiLSTM`, `None`\n",
        "- Test different prediction methods: `CTC`, `Attn`\n",
        "\n",
        "### 4. Data Augmentation\n",
        "- Add rotated, scaled, or slightly distorted versions of images\n",
        "- Include variations in lighting and contrast\n",
        "- Augment rare characters/words to balance the dataset"
      ],
      "metadata": {
        "id": "rwnsyVqenK0M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Next Steps\n",
        "1. Export Your Model: Save the trained model for deployment\n",
        "2. Evaluate on Test Set: Test on completely unseen data\n",
        "3. Fine-tune Further: Iterate on hyperparameters for better performance\n",
        "4. Deploy: Integrate your custom model into production applications"
      ],
      "metadata": {
        "id": "fRnwIT7RpIzA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "- [EasyOCR GitHub Repository](https://github.com/JaidedAI/EasyOCR)\n",
        "- [Deep Text Recognition Benchmark](https://github.com/clovaai/deep-text-recognition-benchmark)\n",
        "- [LMDB Documentation](https://lmdb.readthedocs.io/)"
      ],
      "metadata": {
        "id": "OGSnyI1epPr2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### License\n",
        "This notebook is provided under the MIT License. Feel free to use and modify for your projects.\n",
        "### Contributing\n",
        "Found an issue or have suggestions? Please open an issue or submit a pull request on GitHub."
      ],
      "metadata": {
        "id": "WzSqS6bopxZ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Happy Training! ðŸš€"
      ],
      "metadata": {
        "id": "Yaj75IlMp4W1"
      }
    }
  ]
}